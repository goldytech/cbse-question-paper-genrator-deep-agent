# =============================================================================
# CBSE Question Paper Generator - Environment Configuration Example
# =============================================================================
# Copy this file to .env and update the values with your actual credentials
# cp .env.example .env
# =============================================================================

# =============================================================================
# OPENAI SETTINGS (REQUIRED)
# =============================================================================
# Get your key from: https://platform.openai.com/api-keys
# This is required for both GPT-4o (main agent) and gpt-5-mini (question generation)
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI Embedding Model Settings (Optional - has defaults)
# Model used for generating text embeddings for Qdrant
# OPENAI__EMBEDDING_MODEL=text-embedding-3-large

# Embedding dimensions (3072 for text-embedding-3-large)
# OPENAI__EMBEDDING_DIMENSIONS=3072

# =============================================================================
# QDRANT VECTOR DATABASE SETTINGS (REQUIRED)
# =============================================================================
# Qdrant stores CBSE textbook chunks as vector embeddings
# Install and run Qdrant: https://qdrant.tech/documentation/quick-start/

# Qdrant server host (default: 127.0.0.1 for local Docker)
QDRANT__HOST=127.0.0.1

# Qdrant HTTP port for REST API (check with: docker ps | grep qdrant)
# Docker maps container port 6333 to host port (e.g., 65020)
QDRANT__HTTP_PORT=65020

# Qdrant API Key (Optional - only needed for Qdrant Cloud)
# Leave empty for local Docker instance
# QDRANT__API_KEY=

# Connection timeout in seconds (default: 30)
# QDRANT__TIMEOUT=30

# =============================================================================
# LANGSMITH SETTINGS (OPTIONAL - for tracing and monitoring)
# =============================================================================
# Sign up at: https://smith.langchain.com/
# Helps debug and monitor agent execution
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=lsv2_your_langsmith_key_here
LANGSMITH_PROJECT="cbse-question-paper-generator"

# =============================================================================
# TAVILY SEARCH SETTINGS (OPTIONAL - deprecated)
# =============================================================================
# ⚠️ DEPRECATED: Tavily search has been replaced by Qdrant vector database
# This setting is no longer used but kept for backward compatibility
# TAVILY_API_KEY=tvly-your-tavily-key-here

# =============================================================================
# RETRIEVAL SETTINGS (Optional - has sensible defaults)
# =============================================================================
# These settings control how chunks are retrieved from Qdrant

# Maximum chunks to retrieve per query (default: 10)
# More chunks = more context but higher cost and latency
# RETRIEVAL__MAX_CHUNKS=10

# Minimum similarity score threshold 0.0-1.0 (default: 0.7)
# Higher values = more relevant but fewer results
# RETRIEVAL__SIMILARITY_THRESHOLD=0.7

# Minimum fuzzy match score 0-100 (default: 80)
# For fuzzy topic name matching using rapidfuzz
# RETRIEVAL__FUZZY_MATCH_THRESHOLD=80

# =============================================================================
# LLM QUESTION GENERATION SETTINGS (Optional - has sensible defaults)
# =============================================================================
# These settings control gpt-5-mini question generation

# LLM model for question generation (default: gpt-5-mini)
# Options: gpt-5-mini (recommended), gpt-4o-mini, gpt-4o
# LLM__MODEL=gpt-5-mini

# Temperature for generation 0.0-1.0 (default: 0.3)
# Lower = more consistent and focused questions
# Higher = more creative variety
# Recommended: 0.3 for CBSE exams (consistency is key)
# LLM__TEMPERATURE=0.3

# Maximum tokens for generation (default: 1000)
# MCQ needs ~500 tokens, Long questions need ~1000-1500
# LLM__MAX_TOKENS=1000

# LLM API timeout in seconds (default: 30)
# Increase if you experience timeouts
# LLM__TIMEOUT=30

# Enable quality self-assessment by LLM (default: true)
# LLM will assign a quality_score 0.0-1.0 to each question
# LLM__QUALITY_CHECK_ENABLED=true

# Include few-shot examples in prompts (default: true)
# Provides examples of MCQ, SHORT, LONG formats to LLM
# Improves output quality significantly
# LLM__FEW_SHOT_EXAMPLES_ENABLED=true

# =============================================================================
# TESTING SETTINGS (Optional)
# =============================================================================
# Use these settings for testing without Qdrant

# Use mock data instead of connecting to Qdrant (default: false)
# Useful for testing the LLM generation without vector DB
# USE_MOCK_DATA=false

# Path to mock data file (default: tests/fixtures/mock_qdrant_data.json)
# Contains sample textbook chunks for testing
# MOCK_DATA_PATH=tests/fixtures/mock_qdrant_data.json

# =============================================================================
# QUICK START GUIDE
# =============================================================================
# 1. Set your OpenAI API key (REQUIRED)
# 2. Start Qdrant Docker container:
#    docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
# 3. Check Qdrant ports: docker ps | grep qdrant
# 4. Update QDRANT__HTTP_PORT to match the mapped port (e.g., 65020)
# 5. Run the application: python run.py "Generate Class 10 Mathematics paper"
# =============================================================================
